apiVersion: v1
kind: ConfigMap
metadata:
metadata:
  name: {{ template "fullname" . }}-thresh
  labels:
    app: {{ template "fullname" . }}-thresh
    chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"
    release: "{{ .Release.Name }}"
    heritage: "{{ .Release.Service }}"
data:
  thresh-config.yml: |
    metricSpoutThreads: {{ .Values.thresh.metricSpoutThreads }}
    metricSpoutTasks: {{ .Values.thresh.metricSpoutTasks }}

    statsdConfig:
      host: "127.0.0.1"
      port: 8125
      prefix: monasca.storm.
      dimensions: !!map
        service : monitoring
        component : storm


    metricSpoutConfig:
      kafkaConsumerConfiguration:
      # See http://kafka.apache.org/documentation.html#api for semantics and defaults.
        topic: "metrics"
        numThreads: 1
        groupId: "thresh-metric"
        zookeeperConnect: {{ .Values.zookeeper.uri | quote }}
        consumerId: 1
        socketTimeoutMs: 30000
        socketReceiveBufferBytes : 65536
        fetchMessageMaxBytes: 1048576
        autoCommitEnable: true
        autoCommitIntervalMs: 60000
        queuedMaxMessageChunks: 10
        rebalanceMaxRetries: 4
        fetchMinBytes:  1
        fetchWaitMaxMs:  100
        rebalanceBackoffMs: 2000
        refreshLeaderBackoffMs: 200
        autoOffsetReset: largest
        consumerTimeoutMs:  -1
        clientId : 1
        zookeeperSessionTimeoutMs : 60000
        zookeeperConnectionTimeoutMs : 60000
        zookeeperSyncTimeMs: 2000


    eventSpoutConfig:
      kafkaConsumerConfiguration:
      # See http://kafka.apache.org/documentation.html#api for semantics and defaults.
        topic: "events"
        numThreads: 1
        groupId: "thresh-event"
        zookeeperConnect: {{ .Values.zookeeper.uri | quote }}
        consumerId: 1
        socketTimeoutMs: 30000
        socketReceiveBufferBytes : 65536
        fetchMessageMaxBytes: 1048576
        autoCommitEnable: true
        autoCommitIntervalMs: 60000
        queuedMaxMessageChunks: 10
        rebalanceMaxRetries: 4
        fetchMinBytes:  1
        fetchWaitMaxMs:  100
        rebalanceBackoffMs: 2000
        refreshLeaderBackoffMs: 200
        autoOffsetReset: largest
        consumerTimeoutMs:  -1
        clientId : 1
        zookeeperSessionTimeoutMs : 60000
        zookeeperConnectionTimeoutMs : 60000
        zookeeperSyncTimeMs: 2000


    kafkaProducerConfig:
      # See http://kafka.apache.org/documentation.html#api for semantics and defaults.
      topic: "alarm-state-transitions"
      metadataBrokerList: {{ .Values.kafka.uri | quote }}
      serializerClass: kafka.serializer.StringEncoder
      partitionerClass:
      requestRequiredAcks: 1
      requestTimeoutMs: 10000
      producerType: sync
      keySerializerClass:
      compressionCodec: none
      compressedTopics:
      messageSendMaxRetries: 3
      retryBackoffMs: 100
      topicMetadataRefreshIntervalMs: 600000
      queueBufferingMaxMs: 5000
      queueBufferingMaxMessages: 10000
      queueEnqueueTimeoutMs: -1
      batchNumMessages: 200
      sendBufferBytes: 102400
      clientId : Threshold_Engine


    sporadicMetricNamespaces:
      - foo

    database:
      driverClass: com.mysql.jdbc.Driver
      url: "jdbc:mysql://{{ .Release.Name }}-mysql:{{ .Values.mysql.port }}/{{ .Values.mysql.database }}?useSSL=true"
      user: {{ .Values.mysql.user | quote }}
      password: {{ .Values.mysql.password | quote }}
      properties:
          ssl: false
      # the maximum amount of time to wait on an empty pool before throwing an exception
      maxWaitForConnection: 1s

      # the SQL query to run when validating a connection's liveness
      validationQuery: "/* MyService Health Check */ SELECT 1"

      # the minimum number of connections to keep open
      minSize: 8

      # the maximum number of connections to keep open


      maxSize: 41
